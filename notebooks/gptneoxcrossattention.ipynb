{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464f5d17",
   "metadata": {},
   "source": [
    "# from transformers import AutoImageProcessor,  AutoTokenizer, AutoModelForCausalLM, ViTModel,  BertConfig, ViTConfig, VisionEncoderDecoderConfig, VisionEncoderDecoderModel, VisionEncoderDecoderModel ,ViTImageProcessor\n",
    "\n",
    "from transformers import AutoImageProcessor,  AutoTokenizer, AutoModelForCausalLM, ViTModel,  BertConfig, ViTConfig, VisionEncoderDecoderConfig, VisionEncoderDecoderModel, VisionEncoderDecoderModel ,ViTImageProcessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1626e998",
   "metadata": {},
   "source": [
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"NinedayWang/PolyCoder-0.4B\")\n",
    "image_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NinedayWang/PolyCoder-0.4B\")\n",
    "\n",
    "\n",
    "encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "encoder_config = encoder.config\n",
    "encoder_config.add_cross_attention = True\n",
    "encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\",config = encoder_config)\n",
    "\n",
    "decoder = AutoModelForCausalLM.from_pretrained(\"NinedayWang/PolyCoder-0.4B\")\n",
    "\n",
    "decoder_config = decoder.config\n",
    "decoder_config.add_cross_attention = True\n",
    "\n",
    "decoder = AutoModelForCausalLM.from_pretrained(\"NinedayWang/PolyCoder-0.4B\", config = decoder_config)\n",
    "\n",
    "\n",
    "#import new \n",
    "decoder.forward = types.MethodType(decoder, forward)\n",
    "\n",
    "\"\"\"\n",
    "decoder.q = new.instancemethod(forward, decoder, None)\n",
    "z is z.q()  # true\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Set encoder config hidden size (which will make sure no projection layer is added)\n",
    "setattr(encoder.config, \"is_cross_attention\", True)\n",
    "\"\"\"\n",
    "# Initializing a model with a pretrained Swin as encoder & a pretrained BART-large as decoder\n",
    "model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c13687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor,  AutoTokenizer, AutoModelForCausalLM, ViTModel,  BertConfig, ViTConfig, VisionEncoderDecoderConfig, VisionEncoderDecoderModel, VisionEncoderDecoderModel ,ViTImageProcessor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d22db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "  \"_name_or_path\": \"NinedayWang/PolyCoder-0.4B\",\n",
    "  \"add_cross_attention\": True,\n",
    "  \"architectures\": [\n",
    "    \"GPTNeoXForCausalLM\"\n",
    "  ],\n",
    "  \"bos_token_id\": 0,\n",
    "  \"eos_token_id\": 0,\n",
    "  \"hidden_act\": \"gelu\",\n",
    "  \"hidden_size\": 1024,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 4096,\n",
    "  \"layer_norm_eps\": 1e-05,\n",
    "  \"max_position_embeddings\": 2048,\n",
    "  \"model_type\": \"gpt_neox\",\n",
    "  \"num_attention_heads\": 16,\n",
    "  \"num_hidden_layers\": 24,\n",
    "  \"rotary_emb_base\": 10000,\n",
    "  \"rotary_pct\": 1.0,\n",
    "  \"tie_word_embeddings\": False,\n",
    "  \"tokenizer_class\": \"GPT2Tokenizer\",\n",
    "  \"torch_dtype\": \"float32\",\n",
    "  \"transformers_version\": \"4.27.3\",\n",
    "  \"use_cache\": True,\n",
    "  \"use_parallel_residual\": False,\n",
    "  \"vocab_size\": 50304\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491b750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DesignCoder.model import  GPTNeoXCrossAttentionForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58734e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce137d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab8d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/_designcoder/ were not used when initializing GPTNeoXCrossAttentionForCausalLM: ['gpt_neox.layers.3.attention.query_key_value.weight', 'gpt_neox.layers.7.attention.query_key_value.weight', 'gpt_neox.layers.4.attention.query_key_value.bias', 'gpt_neox.layers.12.attention.query_key_value.bias', 'gpt_neox.layers.1.attention.query_key_value.bias', 'gpt_neox.layers.7.attention.query_key_value.bias', 'gpt_neox.layers.17.attention.query_key_value.weight', 'gpt_neox.layers.16.attention.query_key_value.bias', 'gpt_neox.layers.4.attention.query_key_value.weight', 'gpt_neox.layers.6.attention.query_key_value.weight', 'gpt_neox.layers.14.attention.query_key_value.weight', 'gpt_neox.layers.9.attention.query_key_value.weight', 'gpt_neox.layers.5.attention.query_key_value.bias', 'gpt_neox.layers.20.attention.query_key_value.bias', 'gpt_neox.layers.6.attention.query_key_value.bias', 'gpt_neox.layers.10.attention.query_key_value.bias', 'gpt_neox.layers.15.attention.query_key_value.weight', 'gpt_neox.layers.11.attention.query_key_value.weight', 'gpt_neox.layers.22.attention.query_key_value.weight', 'gpt_neox.layers.13.attention.query_key_value.weight', 'gpt_neox.layers.20.attention.query_key_value.weight', 'gpt_neox.layers.3.attention.query_key_value.bias', 'gpt_neox.layers.0.attention.query_key_value.bias', 'gpt_neox.layers.0.attention.query_key_value.weight', 'gpt_neox.layers.2.attention.query_key_value.weight', 'gpt_neox.layers.22.attention.query_key_value.bias', 'gpt_neox.layers.19.attention.query_key_value.weight', 'gpt_neox.layers.9.attention.query_key_value.bias', 'gpt_neox.layers.11.attention.query_key_value.bias', 'gpt_neox.layers.15.attention.query_key_value.bias', 'gpt_neox.layers.16.attention.query_key_value.weight', 'gpt_neox.layers.8.attention.query_key_value.bias', 'gpt_neox.layers.19.attention.query_key_value.bias', 'gpt_neox.layers.23.attention.query_key_value.weight', 'gpt_neox.layers.5.attention.query_key_value.weight', 'gpt_neox.layers.21.attention.query_key_value.bias', 'gpt_neox.layers.17.attention.query_key_value.bias', 'gpt_neox.layers.23.attention.query_key_value.bias', 'gpt_neox.layers.14.attention.query_key_value.bias', 'gpt_neox.layers.10.attention.query_key_value.weight', 'gpt_neox.layers.8.attention.query_key_value.weight', 'gpt_neox.layers.13.attention.query_key_value.bias', 'gpt_neox.layers.18.attention.query_key_value.weight', 'gpt_neox.layers.2.attention.query_key_value.bias', 'gpt_neox.layers.12.attention.query_key_value.weight', 'gpt_neox.layers.1.attention.query_key_value.weight', 'gpt_neox.layers.18.attention.query_key_value.bias', 'gpt_neox.layers.21.attention.query_key_value.weight']\n",
      "- This IS expected if you are initializing GPTNeoXCrossAttentionForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTNeoXCrossAttentionForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPTNeoXCrossAttentionForCausalLM were not initialized from the model checkpoint at /Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/_designcoder/ and are newly initialized: ['gpt_neox.layers.13.attention.q_attn.weight', 'gpt_neox.layers.5.attention.q_attn.bias', 'gpt_neox.layers.23.attention.c_attn.weight', 'gpt_neox.layers.1.attention.c_attn.weight', 'gpt_neox.layers.20.attention.c_attn.weight', 'gpt_neox.layers.1.attention.q_attn.weight', 'gpt_neox.layers.9.attention.q_attn.weight', 'gpt_neox.layers.18.attention.q_attn.bias', 'gpt_neox.layers.20.attention.q_attn.weight', 'gpt_neox.layers.17.attention.q_attn.bias', 'gpt_neox.layers.2.attention.c_attn.bias', 'gpt_neox.layers.19.attention.c_attn.weight', 'gpt_neox.layers.13.attention.c_attn.bias', 'gpt_neox.layers.18.attention.q_attn.weight', 'gpt_neox.layers.23.attention.q_attn.weight', 'gpt_neox.layers.12.attention.c_attn.weight', 'gpt_neox.layers.10.attention.c_attn.bias', 'gpt_neox.layers.6.attention.q_attn.weight', 'gpt_neox.layers.9.attention.c_attn.weight', 'gpt_neox.layers.5.attention.q_attn.weight', 'gpt_neox.layers.22.attention.q_attn.bias', 'gpt_neox.layers.0.attention.q_attn.weight', 'gpt_neox.layers.14.attention.c_attn.weight', 'gpt_neox.layers.21.attention.c_attn.weight', 'gpt_neox.layers.21.attention.q_attn.bias', 'gpt_neox.layers.14.attention.c_attn.bias', 'gpt_neox.layers.14.attention.q_attn.bias', 'gpt_neox.layers.9.attention.q_attn.bias', 'gpt_neox.layers.2.attention.q_attn.weight', 'gpt_neox.layers.5.attention.c_attn.bias', 'gpt_neox.layers.3.attention.c_attn.bias', 'gpt_neox.layers.7.attention.c_attn.bias', 'gpt_neox.layers.21.attention.q_attn.weight', 'gpt_neox.layers.21.attention.c_attn.bias', 'gpt_neox.layers.3.attention.q_attn.weight', 'gpt_neox.layers.8.attention.c_attn.bias', 'gpt_neox.layers.13.attention.c_attn.weight', 'gpt_neox.layers.1.attention.q_attn.bias', 'gpt_neox.layers.5.attention.c_attn.weight', 'gpt_neox.layers.10.attention.c_attn.weight', 'gpt_neox.layers.11.attention.q_attn.weight', 'gpt_neox.layers.15.attention.q_attn.bias', 'gpt_neox.layers.2.attention.c_attn.weight', 'gpt_neox.layers.7.attention.c_attn.weight', 'gpt_neox.layers.4.attention.q_attn.weight', 'gpt_neox.layers.11.attention.q_attn.bias', 'gpt_neox.layers.2.attention.q_attn.bias', 'gpt_neox.layers.10.attention.q_attn.weight', 'gpt_neox.layers.12.attention.c_attn.bias', 'gpt_neox.layers.7.attention.q_attn.weight', 'gpt_neox.layers.3.attention.q_attn.bias', 'gpt_neox.layers.15.attention.c_attn.bias', 'gpt_neox.layers.22.attention.c_attn.weight', 'gpt_neox.layers.4.attention.c_attn.weight', 'gpt_neox.layers.15.attention.q_attn.weight', 'gpt_neox.layers.16.attention.c_attn.weight', 'gpt_neox.layers.18.attention.c_attn.bias', 'gpt_neox.layers.9.attention.c_attn.bias', 'gpt_neox.layers.1.attention.c_attn.bias', 'gpt_neox.layers.23.attention.c_attn.bias', 'gpt_neox.layers.8.attention.q_attn.bias', 'gpt_neox.layers.4.attention.c_attn.bias', 'gpt_neox.layers.12.attention.q_attn.weight', 'gpt_neox.layers.11.attention.c_attn.weight', 'gpt_neox.layers.17.attention.q_attn.weight', 'gpt_neox.layers.20.attention.q_attn.bias', 'gpt_neox.layers.13.attention.q_attn.bias', 'gpt_neox.layers.16.attention.q_attn.weight', 'gpt_neox.layers.17.attention.c_attn.bias', 'gpt_neox.layers.17.attention.c_attn.weight', 'gpt_neox.layers.8.attention.c_attn.weight', 'gpt_neox.layers.11.attention.c_attn.bias', 'gpt_neox.layers.8.attention.q_attn.weight', 'gpt_neox.layers.6.attention.c_attn.weight', 'gpt_neox.layers.0.attention.q_attn.bias', 'gpt_neox.layers.4.attention.q_attn.bias', 'gpt_neox.layers.22.attention.c_attn.bias', 'gpt_neox.layers.18.attention.c_attn.weight', 'gpt_neox.layers.3.attention.c_attn.weight', 'gpt_neox.layers.10.attention.q_attn.bias', 'gpt_neox.layers.7.attention.q_attn.bias', 'gpt_neox.layers.6.attention.q_attn.bias', 'gpt_neox.layers.6.attention.c_attn.bias', 'gpt_neox.layers.0.attention.c_attn.bias', 'gpt_neox.layers.19.attention.q_attn.weight', 'gpt_neox.layers.16.attention.c_attn.bias', 'gpt_neox.layers.12.attention.q_attn.bias', 'gpt_neox.layers.19.attention.c_attn.bias', 'gpt_neox.layers.22.attention.q_attn.weight', 'gpt_neox.layers.20.attention.c_attn.bias', 'gpt_neox.layers.19.attention.q_attn.bias', 'gpt_neox.layers.15.attention.c_attn.weight', 'gpt_neox.layers.23.attention.q_attn.bias', 'gpt_neox.layers.16.attention.q_attn.bias', 'gpt_neox.layers.14.attention.q_attn.weight', 'gpt_neox.layers.0.attention.c_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from packaging import version\n",
    "assert version.parse(transformers.__version__) >= version.parse(\"4.23.0\")\n",
    "\n",
    "\n",
    "\"\"\"model = GPTNeoXForCausalLM.from_pretrained(\"Code-LMs/Convert2HF/polycoder/0-4B/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NinedayWang/PolyCoder-2.7B\")\n",
    "\"\"\"\n",
    "\n",
    "model_path = \"/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/_designcoder/\"\n",
    "tokenizer_path = \"/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/_designcoder_tokenizer/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "decoder = GPTNeoXCrossAttentionForCausalLM.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc47e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(696)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    694 \u001b[0;31m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    695 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 696 \u001b[0;31m        outputs = self.gpt_neox(\n",
      "\u001b[0m\u001b[0;32m    697 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    698 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> l\n",
      "\u001b[1;32m    691 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    692 \u001b[0m        \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mprediction_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    693 \u001b[0m        ```\"\"\"\n",
      "\u001b[1;32m    694 \u001b[0m        \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    695 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 696 \u001b[0;31m        outputs = self.gpt_neox(\n",
      "\u001b[0m\u001b[1;32m    697 \u001b[0m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    698 \u001b[0m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    699 \u001b[0m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    700 \u001b[0m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    701 \u001b[0m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "ipdb> input_ids\n",
      "tensor([[  319,  4012,  4648,    10,   821,    14,  3689,    14,  2052,    14,\n",
      "           754,  1050,   188,   209,   209,   209, 12113,   260,   280,  2754,\n",
      "           431]])\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(697)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    695 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    696 \u001b[0;31m        outputs = self.gpt_neox(\n",
      "\u001b[0m\u001b[0;32m--> 697 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    698 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    699 \u001b[0;31m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(698)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    696 \u001b[0;31m        outputs = self.gpt_neox(\n",
      "\u001b[0m\u001b[0;32m    697 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 698 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    699 \u001b[0;31m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    700 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(699)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    697 \u001b[0;31m            \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    698 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 699 \u001b[0;31m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    700 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    701 \u001b[0;31m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(700)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    698 \u001b[0;31m            \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    699 \u001b[0;31m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 700 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    701 \u001b[0;31m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    702 \u001b[0;31m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(701)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    699 \u001b[0;31m            \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    700 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 701 \u001b[0;31m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    702 \u001b[0;31m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    703 \u001b[0;31m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(702)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    700 \u001b[0;31m            \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    701 \u001b[0;31m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 702 \u001b[0;31m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    703 \u001b[0;31m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    704 \u001b[0;31m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(703)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    701 \u001b[0;31m            \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    702 \u001b[0;31m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 703 \u001b[0;31m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    704 \u001b[0;31m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    705 \u001b[0;31m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(704)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    702 \u001b[0;31m            \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    703 \u001b[0;31m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 704 \u001b[0;31m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    705 \u001b[0;31m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    706 \u001b[0;31m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(705)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    703 \u001b[0;31m            \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    704 \u001b[0;31m            \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 705 \u001b[0;31m            \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    706 \u001b[0;31m            \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    707 \u001b[0;31m            \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(170)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    168 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 170 \u001b[0;31m            \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    171 \u001b[0;31m            \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    172 \u001b[0;31m            \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> hidden_states\n",
      "tensor([[[ 0.0657,  0.0309,  0.0707,  ...,  0.0846, -0.0547, -0.1183],\n",
      "         [ 0.0549,  0.0609,  0.0541,  ..., -0.0045,  0.0254,  0.0021],\n",
      "         [ 0.0678,  0.0402,  0.0320,  ..., -0.0875, -0.0561,  0.1668],\n",
      "         ...,\n",
      "         [ 0.0009,  0.0971, -0.2026,  ...,  0.0375, -0.0529,  0.0751],\n",
      "         [-0.1385,  0.1208, -0.0751,  ..., -0.0269, -0.1621, -0.0364],\n",
      "         [ 0.0033,  0.1079,  0.0783,  ..., -0.1178, -0.1716, -0.0591]]])\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(171)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    169 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m            \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 171 \u001b[0;31m            \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    172 \u001b[0;31m            \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> query\n",
      "tensor([[[-0.0575, -0.0162, -0.0622,  ..., -0.0742,  0.0085, -0.0249],\n",
      "         [ 0.0435, -0.0580,  0.0759,  ..., -0.0144,  0.0416, -0.0273],\n",
      "         [ 0.0784, -0.1063, -0.0254,  ..., -0.0208, -0.0395, -0.0156],\n",
      "         ...,\n",
      "         [ 0.0249,  0.0434, -0.0332,  ...,  0.0162, -0.0833,  0.0691],\n",
      "         [-0.0139,  0.0210, -0.0703,  ..., -0.0262, -0.0604, -0.0421],\n",
      "         [-0.0303, -0.0511, -0.1058,  ...,  0.0506,  0.0024, -0.0088]]])\n",
      "ipdb> query.shape\n",
      "torch.Size([1, 21, 1024])\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/mehmetburaksayici/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py\u001b[0m(172)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    170 \u001b[0;31m            \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    171 \u001b[0;31m            \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 172 \u001b[0;31m            \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    174 \u001b[0;31m        \u001b[0;31m# [batch, seq_len, (num_heads * 3 * head_size)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> key\n",
      "tensor([[[ 0.0008, -0.0815,  0.0404,  ..., -0.1052,  0.0298,  0.0203],\n",
      "         [-0.0113,  0.1102,  0.0212,  ..., -0.0809, -0.0792,  0.0186],\n",
      "         [ 0.0515,  0.0198, -0.0423,  ..., -0.0293,  0.1142,  0.0658],\n",
      "         ...,\n",
      "         [-0.0287,  0.0423,  0.0011,  ..., -0.0193, -0.0143,  0.1136],\n",
      "         [-0.0556,  0.0511, -0.0658,  ..., -0.0754, -0.0116,  0.0160],\n",
      "         [-0.0276, -0.0003,  0.0034,  ..., -0.0815, -0.0195, -0.0426]]])\n",
      "ipdb> value\n",
      "tensor([[[ 8.8616e-03,  4.9839e-02,  4.8271e-03,  ..., -6.3613e-03,\n",
      "          -6.0335e-02, -5.7941e-02],\n",
      "         [ 4.3684e-02,  3.6311e-02, -8.8437e-04,  ..., -7.3496e-02,\n",
      "          -3.7260e-02, -8.1043e-02],\n",
      "         [ 8.2005e-03, -5.9728e-03,  8.4866e-03,  ..., -7.9448e-02,\n",
      "           7.3352e-02, -6.4748e-02],\n",
      "         ...,\n",
      "         [-1.5172e-03,  4.2060e-02,  6.0357e-02,  ..., -1.2680e-02,\n",
      "           7.8968e-02, -3.9851e-05],\n",
      "         [ 6.5510e-02, -1.6118e-02,  1.4211e-01,  ..., -5.1410e-02,\n",
      "           1.4962e-01, -1.5451e-01],\n",
      "         [-3.0104e-02,  1.0132e-02,  6.4527e-02,  ..., -2.1215e-02,\n",
      "           8.4619e-02,  4.3523e-02]]])\n",
      "ipdb> key.shape\n",
      "torch.Size([1, 42, 1024])\n",
      "ipdb> vlaue.shape\n",
      "*** NameError: name 'vlaue' is not defined\n",
      "ipdb> value.shape\n",
      "torch.Size([1, 42, 1024])\n",
      "ipdb> query.shape\n",
      "torch.Size([1, 21, 1024])\n",
      "ipdb> torch.cat((hidden_states,hidden_states),1).shape\n",
      "torch.Size([1, 42, 1024])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(self.hidden_size, dim=2)[0].shape\n",
      "torch.Size([1, 42, 1024])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split()\n",
      "*** TypeError: split() missing 1 required positional argument: 'split_size'\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(2)\n",
      "(tensor([[[ 8.2566e-04, -8.1479e-02,  4.0403e-02,  ..., -6.3613e-03,\n",
      "          -6.0335e-02, -5.7941e-02],\n",
      "         [-1.1288e-02,  1.1022e-01,  2.1230e-02,  ..., -7.3496e-02,\n",
      "          -3.7260e-02, -8.1043e-02],\n",
      "         [ 5.1535e-02,  1.9789e-02, -4.2269e-02,  ..., -7.9448e-02,\n",
      "           7.3352e-02, -6.4748e-02],\n",
      "         ...,\n",
      "         [-2.8733e-02,  4.2331e-02,  1.0896e-03,  ..., -1.2680e-02,\n",
      "           7.8968e-02, -3.9851e-05],\n",
      "         [-5.5587e-02,  5.1064e-02, -6.5839e-02,  ..., -5.1410e-02,\n",
      "           1.4962e-01, -1.5451e-01],\n",
      "         [-2.7633e-02, -2.5278e-04,  3.4301e-03,  ..., -2.1215e-02,\n",
      "           8.4619e-02,  4.3523e-02]]]),)\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(2)[0].shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'tuple' object has no attribute 'shape'\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1)[0].shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> query.shape\n",
      "torch.Size([1, 21, 1024])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,2).shape\n",
      "*** AttributeError: 'tuple' object has no attribute 'shape'\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,2)[0].shape\n",
      "torch.Size([1, 42, 1])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,2)[0].shape\n",
      "torch.Size([1, 42, 1])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,3)[0].shape\n",
      "*** IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,0)[0].shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split(1,1)[0].shape\n",
      "torch.Size([1, 1, 2048])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> query.shape\n",
      "torch.Size([1, 21, 1024])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).shape\n",
      "torch.Size([1, 42, 2048])\n",
      "ipdb> self.c_attn(torch.cat((hidden_states,hidden_states),1)).split()\n",
      "*** TypeError: split() missing 1 required positional argument: 'split_size'\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 105, 16, 192]' is invalid for input of size 107520",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mdef binarySearch(arr, left, right, x):\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124m    mid = (left +\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      3\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(res))\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/transformers/generation/utils.py:1406\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1401\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_return_sequences has to be 1, but is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when doing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1402\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m greedy search.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1403\u001b[0m         )\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/transformers/generation/utils.py:2201\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2198\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2201\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2204\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2209\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py:696\u001b[0m, in \u001b[0;36mGPTNeoXCrossAttentionForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    694\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdb\u001b[39;00m; pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[0;32m--> 696\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_neox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    711\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_out(hidden_states)\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py:589\u001b[0m, in \u001b[0;36mGPTNeoXCrossAttentionModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    580\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    581\u001b[0m         create_custom_forward(layer),\n\u001b[1;32m    582\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_attention_mask \u001b[38;5;66;03m# new addition\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# new addition\u001b[39;49;00m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# new addition\u001b[39;49;00m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py:377\u001b[0m, in \u001b[0;36mGPTNeoXCrossAttentionLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, use_cache, layer_past, output_attentions, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    368\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    376\u001b[0m ):\n\u001b[0;32m--> 377\u001b[0m     attention_layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attention_layer_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: attn_output, present, (attn_weights)\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m attention_layer_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/sahibinden/ccrraawwll/DesignCoder/model.py:172\u001b[0m, in \u001b[0;36mGPTNeoXCrossAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, layer_past, use_cache, output_attentions, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    170\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_attn(hidden_states)\n\u001b[1;32m    171\u001b[0m     key, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_attn(torch\u001b[38;5;241m.\u001b[39mcat((hidden_states,hidden_states),\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m     qkv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((query,key,value),\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# [batch, seq_len, (num_heads * 3 * head_size)]\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m#   --> [batch, seq_len, num_heads, 3 * head_size]\u001b[39;00m\n\u001b[1;32m    176\u001b[0m new_qkv_shape \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_attention_heads, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 105, 16, 192]' is invalid for input of size 107520"
     ]
    }
   ],
   "source": [
    "prompt = '''def binarySearch(arr, left, right, x):\n",
    "    mid = (left +'''\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "result = decoder.generate(input_ids, max_length=50, num_beams=1, num_return_sequences=1)\n",
    "for res in result:\n",
    "    print(tokenizer.decode(res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e95f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "107520/192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "105*16*192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"NinedayWang/PolyCoder-0.4B\")\n",
    "image_processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"NinedayWang/PolyCoder-0.4B\")\n",
    "\n",
    "\n",
    "encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\n",
    "encoder_config = encoder.config\n",
    "encoder_config.add_cross_attention = True\n",
    "encoder = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\",config = encoder_config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initializing a model with a pretrained Swin as encoder & a pretrained BART-large as decoder\n",
    "model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b972a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import * \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import io, transforms\n",
    "import torchvision.datasets as dset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import EncoderDecoderModel, GPT2Tokenizer, ViTFeatureExtractor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7883fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MEAN = (0.485, 0.456, 0.406)\n",
    "STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "TRAIN_PCT = 0.95\n",
    "NUM_WORKERS = 2\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LR = 1e-4\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "MAX_TEXT_LENGTH = 32\n",
    "\n",
    "LABEL_MASK = -100\n",
    "\n",
    "TOP_K = 1000\n",
    "TOP_P = 0.95\n",
    "\n",
    "\n",
    "tfms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMAGE_SIZE), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=0.5, \n",
    "            std=0.5\n",
    "        )\n",
    "   ]\n",
    ")\n",
    "descale = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize(\n",
    "            mean = [ 0., 0., 0. ],\n",
    "            std = 1 / 0.5\n",
    "        ),\n",
    "        transforms.Normalize(\n",
    "            mean = -0.5,\n",
    "            std = [ 1., 1., 1. ]\n",
    "        ),                           \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "images =  Image.fromarray(np.zeros((224,224,3)).astype(np.uint8))\n",
    "\n",
    "pixel_values = image_processor(images).pixel_values\n",
    "inp_ = torch.from_numpy(pixel_values[0])[None,]\n",
    "encoder_outputs = encoder(inp_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e1bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ = torch.from_numpy(pixel_values[0])[None,]\n",
    "model.generate(inp_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891499a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.gpt_neox.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54865801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cec94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c448b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7dd8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d6d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed6215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76807af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286f826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f332620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65642b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "def generate_sentence_from_image(model, encoder_outputs, tokenizer, max_text_length: int, device)-> List[str]:\n",
    "    generated_so_far = torch.LongTensor([[tokenizer.bos_token_id]]*len(encoder_outputs.last_hidden_state)).to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in tqdm(range(max_text_length)):\n",
    "            attention_mask = torch.ones_like(generated_so_far)\n",
    "            decoder_out = model(\n",
    "                decoder_input_ids=generated_so_far, \n",
    "                decoder_attention_mask=attention_mask,\n",
    "                encoder_outputs=encoder_outputs\n",
    "            )\n",
    "\n",
    "            next_token_logits = decoder_out[\"logits\"][:, -1, :]\n",
    "            filtered_p = top_k_top_p_filtering(next_token_logits, top_k=TOP_K, top_p=TOP_P, device=device)\n",
    "            next_token = torch.multinomial(filtered_p, num_samples=1)\n",
    "            generated_so_far = torch.cat((generated_so_far, next_token), dim=1)\n",
    "\n",
    "    return [tokenizer.decode(coded_sentence) for coded_sentence in generated_so_far]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images =  Image.fromarray(np.zeros((224,224,3)).astype(np.uint8))\n",
    "\n",
    "pixel_values = image_processor(images).pixel_values\n",
    "\n",
    "encoder_outputs = model.encoder(pixel_values=tfms(images)[None,:])\n",
    "\n",
    "\n",
    "\n",
    "generated_sentences = generate_sentence_from_image(\n",
    "                  model, \n",
    "                encoder_outputs, \n",
    "                tokenizer, \n",
    "                MAX_TEXT_LENGTH,\n",
    "                \"cpu\"\n",
    "            )\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
